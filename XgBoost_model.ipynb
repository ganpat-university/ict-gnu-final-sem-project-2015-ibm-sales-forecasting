{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import operator\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\") #Needed to save figures\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_map(features):\n",
    "    outfile = open('xgb.fmap', 'w')\n",
    "    for i, feat in enumerate(features):\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "    outfile.close()\n",
    "\n",
    "def rmspe(y, yhat):\n",
    "    return np.sqrt(np.mean((yhat/y-1) ** 2))\n",
    "\n",
    "def rmspe_xg(yhat, y):\n",
    "    y = np.expm1(y.get_label())\n",
    "    yhat = np.expm1(yhat)\n",
    "    return \"rmspe\", rmspe(y,yhat)\n",
    "\n",
    "# Gather some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(features, data):\n",
    "    # remove NaNs\n",
    "    data.fillna(0, inplace=True)\n",
    "    data.loc[data.Open.isnull(), 'Open'] = 1\n",
    "    # Use some properties directly\n",
    "    features.extend(['Store', 'CompetitionDistance', 'Promo', 'SchoolHoliday'])\n",
    "\n",
    "    # Label encode some features\n",
    "    features.extend(['StoreType', 'Assortment', 'StateHoliday'])\n",
    "    mappings = {'0':0, 'a':1, 'b':2, 'c':3, 'd':4}\n",
    "    data.StoreType.replace(mappings, inplace=True)\n",
    "    data.Assortment.replace(mappings, inplace=True)\n",
    "    data.StateHoliday.replace(mappings, inplace=True)\n",
    "\n",
    "    features.extend(['DayOfWeek', 'Month', 'Day', 'Year', 'WeekOfYear'])\n",
    "    data['Year'] = data.Date.dt.year\n",
    "    data['Month'] = data.Date.dt.month\n",
    "    data['Day'] = data.Date.dt.day\n",
    "    data['DayOfWeek'] = data.Date.dt.dayofweek\n",
    "    data['WeekOfYear'] = data.Date.dt.weekofyear\n",
    "\n",
    "    \n",
    "    features.append('CompetitionOpen')\n",
    "    data['CompetitionOpen'] = 12 * (data.Year - data.CompetitionOpenSinceYear) + \\\n",
    "        (data.Month - data.CompetitionOpenSinceMonth)\n",
    "    # Promo open time in months\n",
    "    features.append('PromoOpen')\n",
    "    data['PromoOpen'] = 12 * (data.Year - data.Promo2SinceYear) + \\\n",
    "        (data.WeekOfYear - data.Promo2SinceWeek) / 4.0\n",
    "    data['PromoOpen'] = data.PromoOpen.apply(lambda x: x if x > 0 else 0)\n",
    "    data.loc[data.Promo2SinceYear == 0, 'PromoOpen'] = 0\n",
    "\n",
    "    # Indicate that sales on that day are in promo interval\n",
    "    features.append('IsPromoMonth')\n",
    "    month2str = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', \\\n",
    "             7:'Jul', 8:'Aug', 9:'Sept', 10:'Oct', 11:'Nov', 12:'Dec'}\n",
    "    data['monthStr'] = data.Month.map(month2str)\n",
    "    data.loc[data.PromoInterval == 0, 'PromoInterval'] = ''\n",
    "    data['IsPromoMonth'] = 0\n",
    "    for interval in data.PromoInterval.unique():\n",
    "        if interval != '':\n",
    "            for month in interval.split(','):\n",
    "                data.loc[(data.monthStr == month) & (data.PromoInterval == interval), 'IsPromoMonth'] = 1\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the training, test and store data using pandas\n"
     ]
    }
   ],
   "source": [
    "print(\"Load the training, test and store data using pandas\")\n",
    "types = {'CompetitionOpenSinceYear': np.dtype(int),\n",
    "         'CompetitionOpenSinceMonth': np.dtype(int),\n",
    "         'StateHoliday': np.dtype(str),\n",
    "         'Promo2SinceWeek': np.dtype(int),\n",
    "         'SchoolHoliday': np.dtype(float),\n",
    "         'PromoInterval': np.dtype(str)}\n",
    "train = pd.read_csv(\"train.csv\", parse_dates=[2], dtype=types)\n",
    "test = pd.read_csv(\"test.csv\", parse_dates=[3], dtype=types)\n",
    "store = pd.read_csv(\"store.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assume store open, if not provided\n",
      "Consider only open stores for training. Closed stores wont count into the score.\n",
      "Use only Sales bigger then zero. Simplifies calculation of rmspe\n",
      "Join with store\n",
      "augment features\n",
      "['Store', 'CompetitionDistance', 'Promo', 'Promo2', 'SchoolHoliday', 'StoreType', 'Assortment', 'StateHoliday', 'DayOfWeek', 'Month', 'Day', 'Year', 'WeekOfYear', 'CompetitionOpen', 'PromoOpen', 'IsPromoMonth']\n"
     ]
    }
   ],
   "source": [
    "print(\"Assume store open, if not provided\")\n",
    "train.fillna(1, inplace=True)\n",
    "test.fillna(1, inplace=True)\n",
    "\n",
    "print(\"Consider only open stores for training. Closed stores wont count into the score.\")\n",
    "train = train[train[\"Open\"] != 0]\n",
    "print(\"Use only Sales bigger then zero. Simplifies calculation of rmspe\")\n",
    "train = train[train[\"Sales\"] > 0]\n",
    "\n",
    "print(\"Join with store\")\n",
    "train = pd.merge(train, store, on='Store')\n",
    "test = pd.merge(test, store, on='Store')\n",
    "\n",
    "features = []\n",
    "\n",
    "print(\"augment features\")\n",
    "build_features(features, train)\n",
    "build_features([], test)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data processed\n"
     ]
    }
   ],
   "source": [
    "print('training data processed')\n",
    "\n",
    "params = {\"objective\": \"reg:linear\",\n",
    "          \"booster\" : \"gbtree\",\n",
    "          \"eta\": 0.3,\n",
    "          \"max_depth\": 10,\n",
    "          \"subsample\": 0.9,\n",
    "          \"colsample_bytree\": 0.7,\n",
    "          \"silent\": 1,\n",
    "          \"seed\": 1301\n",
    "          }\n",
    "num_boost_round = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train a XGBoost model\n",
      "[0]\ttrain-rmse:5.79368\teval-rmse:5.79362\ttrain-rmspe:0.99684\teval-rmspe:0.996838\n",
      "Multiple eval metrics have been passed: 'eval-rmspe' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmspe hasn't improved in 100 rounds.\n",
      "[1]\ttrain-rmse:4.06275\teval-rmse:4.06366\ttrain-rmspe:0.981524\teval-rmspe:0.981525\n",
      "[2]\ttrain-rmse:2.85319\teval-rmse:2.85523\ttrain-rmspe:0.938095\teval-rmspe:0.938159\n",
      "[3]\ttrain-rmse:2.00969\teval-rmse:2.01187\ttrain-rmspe:0.856661\teval-rmspe:0.856648\n",
      "[4]\ttrain-rmse:1.42234\teval-rmse:1.42514\ttrain-rmspe:0.74415\teval-rmspe:0.743779\n",
      "[5]\ttrain-rmse:1.01698\teval-rmse:1.02011\ttrain-rmspe:0.619457\teval-rmspe:0.617958\n",
      "[6]\ttrain-rmse:0.741238\teval-rmse:0.744666\ttrain-rmspe:0.503996\teval-rmspe:0.500151\n",
      "[7]\ttrain-rmse:0.55319\teval-rmse:0.556665\ttrain-rmspe:0.411686\teval-rmspe:0.403568\n",
      "[8]\ttrain-rmse:0.430897\teval-rmse:0.434265\ttrain-rmspe:0.348815\teval-rmspe:0.335589\n",
      "[9]\ttrain-rmse:0.352225\teval-rmse:0.35527\ttrain-rmspe:0.311021\teval-rmspe:0.292855\n",
      "[10]\ttrain-rmse:0.307511\teval-rmse:0.310194\ttrain-rmspe:0.295619\teval-rmspe:0.272411\n",
      "[11]\ttrain-rmse:0.275826\teval-rmse:0.27772\ttrain-rmspe:0.284665\teval-rmspe:0.25718\n",
      "[12]\ttrain-rmse:0.251518\teval-rmse:0.253037\ttrain-rmspe:0.275465\teval-rmspe:0.244966\n",
      "[13]\ttrain-rmse:0.242812\teval-rmse:0.244332\ttrain-rmspe:0.276667\teval-rmspe:0.244639\n",
      "[14]\ttrain-rmse:0.234528\teval-rmse:0.235563\ttrain-rmspe:0.275942\teval-rmspe:0.241562\n",
      "[15]\ttrain-rmse:0.223373\teval-rmse:0.224315\ttrain-rmspe:0.269701\teval-rmspe:0.233949\n",
      "[16]\ttrain-rmse:0.220185\teval-rmse:0.221362\ttrain-rmspe:0.2669\teval-rmspe:0.23365\n",
      "[17]\ttrain-rmse:0.216744\teval-rmse:0.218471\ttrain-rmspe:0.266749\teval-rmspe:0.232864\n",
      "[18]\ttrain-rmse:0.215428\teval-rmse:0.217044\ttrain-rmspe:0.267142\teval-rmspe:0.232552\n",
      "[19]\ttrain-rmse:0.206392\teval-rmse:0.207844\ttrain-rmspe:0.259608\teval-rmspe:0.223182\n",
      "[20]\ttrain-rmse:0.194653\teval-rmse:0.195929\ttrain-rmspe:0.249311\teval-rmspe:0.20953\n",
      "[21]\ttrain-rmse:0.191912\teval-rmse:0.193056\ttrain-rmspe:0.240392\teval-rmspe:0.206564\n",
      "[22]\ttrain-rmse:0.188606\teval-rmse:0.189804\ttrain-rmspe:0.237577\teval-rmspe:0.203451\n",
      "[23]\ttrain-rmse:0.179711\teval-rmse:0.18083\ttrain-rmspe:0.229228\teval-rmspe:0.193264\n",
      "[24]\ttrain-rmse:0.173794\teval-rmse:0.174773\ttrain-rmspe:0.223974\teval-rmspe:0.186721\n",
      "[25]\ttrain-rmse:0.166747\teval-rmse:0.167399\ttrain-rmspe:0.217969\teval-rmspe:0.178941\n",
      "[26]\ttrain-rmse:0.165589\teval-rmse:0.166084\ttrain-rmspe:0.216835\teval-rmspe:0.177576\n",
      "[27]\ttrain-rmse:0.16429\teval-rmse:0.164911\ttrain-rmspe:0.215735\teval-rmspe:0.176452\n",
      "[28]\ttrain-rmse:0.162709\teval-rmse:0.163566\ttrain-rmspe:0.213556\teval-rmspe:0.174903\n",
      "[29]\ttrain-rmse:0.162102\teval-rmse:0.163022\ttrain-rmspe:0.213263\teval-rmspe:0.17442\n",
      "[30]\ttrain-rmse:0.160541\teval-rmse:0.161519\ttrain-rmspe:0.210756\teval-rmspe:0.172956\n",
      "[31]\ttrain-rmse:0.156604\teval-rmse:0.157741\ttrain-rmspe:0.207272\teval-rmspe:0.168989\n",
      "[32]\ttrain-rmse:0.15608\teval-rmse:0.157142\ttrain-rmspe:0.207241\teval-rmspe:0.168397\n",
      "[33]\ttrain-rmse:0.154056\teval-rmse:0.155223\ttrain-rmspe:0.205588\teval-rmspe:0.166408\n",
      "[34]\ttrain-rmse:0.151089\teval-rmse:0.152181\ttrain-rmspe:0.202192\teval-rmspe:0.163065\n",
      "[35]\ttrain-rmse:0.146817\teval-rmse:0.148092\ttrain-rmspe:0.198803\teval-rmspe:0.158176\n",
      "[36]\ttrain-rmse:0.142666\teval-rmse:0.143942\ttrain-rmspe:0.195104\teval-rmspe:0.153873\n",
      "[37]\ttrain-rmse:0.139923\teval-rmse:0.141452\ttrain-rmspe:0.19231\teval-rmspe:0.151101\n",
      "[38]\ttrain-rmse:0.138961\teval-rmse:0.140526\ttrain-rmspe:0.191502\teval-rmspe:0.150104\n",
      "[39]\ttrain-rmse:0.136994\teval-rmse:0.138649\ttrain-rmspe:0.189653\teval-rmspe:0.148142\n",
      "[40]\ttrain-rmse:0.135891\teval-rmse:0.137774\ttrain-rmspe:0.188633\teval-rmspe:0.147234\n",
      "[41]\ttrain-rmse:0.135287\teval-rmse:0.137246\ttrain-rmspe:0.185898\teval-rmspe:0.146614\n",
      "[42]\ttrain-rmse:0.134475\teval-rmse:0.136586\ttrain-rmspe:0.184864\teval-rmspe:0.145924\n",
      "[43]\ttrain-rmse:0.133406\teval-rmse:0.135593\ttrain-rmspe:0.183886\teval-rmspe:0.144851\n",
      "[44]\ttrain-rmse:0.132295\teval-rmse:0.134522\ttrain-rmspe:0.182981\teval-rmspe:0.143795\n",
      "[45]\ttrain-rmse:0.130954\teval-rmse:0.133216\ttrain-rmspe:0.181854\teval-rmspe:0.142404\n",
      "[46]\ttrain-rmse:0.129176\teval-rmse:0.131272\ttrain-rmspe:0.179796\teval-rmspe:0.140402\n",
      "[47]\ttrain-rmse:0.128637\teval-rmse:0.130888\ttrain-rmspe:0.179295\teval-rmspe:0.140004\n",
      "[48]\ttrain-rmse:0.127171\teval-rmse:0.129469\ttrain-rmspe:0.178017\teval-rmspe:0.13849\n",
      "[49]\ttrain-rmse:0.126364\teval-rmse:0.12872\ttrain-rmspe:0.177289\teval-rmspe:0.137699\n",
      "[50]\ttrain-rmse:0.12608\teval-rmse:0.128486\ttrain-rmspe:0.161894\teval-rmspe:0.137451\n",
      "[51]\ttrain-rmse:0.125612\teval-rmse:0.128142\ttrain-rmspe:0.161327\teval-rmspe:0.137136\n",
      "[52]\ttrain-rmse:0.125319\teval-rmse:0.127929\ttrain-rmspe:0.160861\teval-rmspe:0.136874\n",
      "[53]\ttrain-rmse:0.124157\teval-rmse:0.126817\ttrain-rmspe:0.159877\teval-rmspe:0.135681\n",
      "[54]\ttrain-rmse:0.123294\teval-rmse:0.126155\ttrain-rmspe:0.159134\teval-rmspe:0.134957\n",
      "[55]\ttrain-rmse:0.122945\teval-rmse:0.125807\ttrain-rmspe:0.158925\teval-rmspe:0.134513\n",
      "[56]\ttrain-rmse:0.122318\teval-rmse:0.125283\ttrain-rmspe:0.158356\teval-rmspe:0.133927\n",
      "[57]\ttrain-rmse:0.121192\teval-rmse:0.124097\ttrain-rmspe:0.15735\teval-rmspe:0.13258\n",
      "[58]\ttrain-rmse:0.120819\teval-rmse:0.123787\ttrain-rmspe:0.152914\teval-rmspe:0.132184\n",
      "[59]\ttrain-rmse:0.120577\teval-rmse:0.123584\ttrain-rmspe:0.152692\teval-rmspe:0.131967\n",
      "[60]\ttrain-rmse:0.119769\teval-rmse:0.122734\ttrain-rmspe:0.152414\teval-rmspe:0.131033\n",
      "[61]\ttrain-rmse:0.118812\teval-rmse:0.12187\ttrain-rmspe:0.151478\teval-rmspe:0.130111\n",
      "[62]\ttrain-rmse:0.117788\teval-rmse:0.120989\ttrain-rmspe:0.150608\teval-rmspe:0.129251\n",
      "[63]\ttrain-rmse:0.11733\teval-rmse:0.120544\ttrain-rmspe:0.150114\teval-rmspe:0.128666\n",
      "[64]\ttrain-rmse:0.116313\teval-rmse:0.119611\ttrain-rmspe:0.149193\teval-rmspe:0.127577\n",
      "[65]\ttrain-rmse:0.115276\teval-rmse:0.11874\ttrain-rmspe:0.148257\teval-rmspe:0.126631\n",
      "[66]\ttrain-rmse:0.114465\teval-rmse:0.117844\ttrain-rmspe:0.147461\teval-rmspe:0.125619\n",
      "[67]\ttrain-rmse:0.114115\teval-rmse:0.117566\ttrain-rmspe:0.147321\teval-rmspe:0.125282\n",
      "[68]\ttrain-rmse:0.113719\teval-rmse:0.11713\ttrain-rmspe:0.146953\teval-rmspe:0.124772\n",
      "[69]\ttrain-rmse:0.113275\teval-rmse:0.116657\ttrain-rmspe:0.146518\teval-rmspe:0.124221\n",
      "[70]\ttrain-rmse:0.112682\teval-rmse:0.116134\ttrain-rmspe:0.145121\teval-rmspe:0.123676\n",
      "[71]\ttrain-rmse:0.112116\teval-rmse:0.11574\ttrain-rmspe:0.143942\teval-rmspe:0.123238\n",
      "[72]\ttrain-rmse:0.111308\teval-rmse:0.115048\ttrain-rmspe:0.139635\teval-rmspe:0.122541\n",
      "[73]\ttrain-rmse:0.110426\teval-rmse:0.114194\ttrain-rmspe:0.138828\teval-rmspe:0.121599\n",
      "[74]\ttrain-rmse:0.109918\teval-rmse:0.113724\ttrain-rmspe:0.138283\teval-rmspe:0.121128\n",
      "[75]\ttrain-rmse:0.109533\teval-rmse:0.113424\ttrain-rmspe:0.137718\teval-rmspe:0.120859\n",
      "[76]\ttrain-rmse:0.109306\teval-rmse:0.113254\ttrain-rmspe:0.137522\teval-rmspe:0.120687\n",
      "[77]\ttrain-rmse:0.109007\teval-rmse:0.11293\ttrain-rmspe:0.137256\teval-rmspe:0.120412\n",
      "[78]\ttrain-rmse:0.108765\teval-rmse:0.112693\ttrain-rmspe:0.137011\teval-rmspe:0.120136\n",
      "[79]\ttrain-rmse:0.108444\teval-rmse:0.112396\ttrain-rmspe:0.136715\teval-rmspe:0.119821\n",
      "[80]\ttrain-rmse:0.107991\teval-rmse:0.111995\ttrain-rmspe:0.136246\teval-rmspe:0.119346\n",
      "[81]\ttrain-rmse:0.107646\teval-rmse:0.111723\ttrain-rmspe:0.135615\teval-rmspe:0.119068\n",
      "[82]\ttrain-rmse:0.107178\teval-rmse:0.111361\ttrain-rmspe:0.13513\teval-rmspe:0.118733\n",
      "[83]\ttrain-rmse:0.106658\teval-rmse:0.110994\ttrain-rmspe:0.134245\teval-rmspe:0.118229\n",
      "[84]\ttrain-rmse:0.106165\teval-rmse:0.110532\ttrain-rmspe:0.133545\teval-rmspe:0.117754\n",
      "[85]\ttrain-rmse:0.105739\teval-rmse:0.110175\ttrain-rmspe:0.133158\teval-rmspe:0.117255\n",
      "[86]\ttrain-rmse:0.104998\teval-rmse:0.109452\ttrain-rmspe:0.132476\teval-rmspe:0.11651\n",
      "[87]\ttrain-rmse:0.104759\teval-rmse:0.109313\ttrain-rmspe:0.13224\teval-rmspe:0.116351\n",
      "[88]\ttrain-rmse:0.104523\teval-rmse:0.109103\ttrain-rmspe:0.131999\teval-rmspe:0.116155\n",
      "[89]\ttrain-rmse:0.103918\teval-rmse:0.108725\ttrain-rmspe:0.129809\teval-rmspe:0.115764\n",
      "[90]\ttrain-rmse:0.103491\teval-rmse:0.108425\ttrain-rmspe:0.129415\teval-rmspe:0.11538\n",
      "[91]\ttrain-rmse:0.103188\teval-rmse:0.108244\ttrain-rmspe:0.128968\teval-rmspe:0.115219\n",
      "[92]\ttrain-rmse:0.103022\teval-rmse:0.108132\ttrain-rmspe:0.128758\teval-rmspe:0.115093\n",
      "[93]\ttrain-rmse:0.1027\teval-rmse:0.107854\ttrain-rmspe:0.128452\teval-rmspe:0.114836\n",
      "[94]\ttrain-rmse:0.102259\teval-rmse:0.107483\ttrain-rmspe:0.128046\teval-rmspe:0.114388\n",
      "[95]\ttrain-rmse:0.102131\teval-rmse:0.107387\ttrain-rmspe:0.127927\teval-rmspe:0.11428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[96]\ttrain-rmse:0.10148\teval-rmse:0.106777\ttrain-rmspe:0.127281\teval-rmspe:0.113493\n",
      "[97]\ttrain-rmse:0.101183\teval-rmse:0.106541\ttrain-rmspe:0.127007\teval-rmspe:0.113204\n",
      "[98]\ttrain-rmse:0.101056\teval-rmse:0.106426\ttrain-rmspe:0.12692\teval-rmspe:0.113044\n",
      "[99]\ttrain-rmse:0.100873\teval-rmse:0.106307\ttrain-rmspe:0.126697\teval-rmspe:0.112928\n",
      "[100]\ttrain-rmse:0.100556\teval-rmse:0.106075\ttrain-rmspe:0.126348\teval-rmspe:0.112672\n",
      "[101]\ttrain-rmse:0.100179\teval-rmse:0.105782\ttrain-rmspe:0.125751\teval-rmspe:0.112239\n",
      "[102]\ttrain-rmse:0.099906\teval-rmse:0.10548\ttrain-rmspe:0.125471\teval-rmspe:0.111937\n",
      "[103]\ttrain-rmse:0.099658\teval-rmse:0.105214\ttrain-rmspe:0.125252\teval-rmspe:0.111513\n",
      "[104]\ttrain-rmse:0.099494\teval-rmse:0.105093\ttrain-rmspe:0.125105\teval-rmspe:0.111386\n",
      "[105]\ttrain-rmse:0.099302\teval-rmse:0.104929\ttrain-rmspe:0.124931\teval-rmspe:0.111201\n",
      "[106]\ttrain-rmse:0.099129\teval-rmse:0.104842\ttrain-rmspe:0.123911\teval-rmspe:0.111085\n",
      "[107]\ttrain-rmse:0.098929\teval-rmse:0.104684\ttrain-rmspe:0.122602\teval-rmspe:0.110861\n",
      "[108]\ttrain-rmse:0.098582\teval-rmse:0.104554\ttrain-rmspe:0.120525\teval-rmspe:0.110734\n",
      "[109]\ttrain-rmse:0.098375\teval-rmse:0.104435\ttrain-rmspe:0.120323\teval-rmspe:0.110616\n",
      "[110]\ttrain-rmse:0.098171\teval-rmse:0.104317\ttrain-rmspe:0.120007\teval-rmspe:0.11048\n",
      "[111]\ttrain-rmse:0.097917\teval-rmse:0.104005\ttrain-rmspe:0.119739\teval-rmspe:0.109826\n",
      "[112]\ttrain-rmse:0.097394\teval-rmse:0.10351\ttrain-rmspe:0.119198\teval-rmspe:0.109037\n",
      "[113]\ttrain-rmse:0.096988\teval-rmse:0.103237\ttrain-rmspe:0.118549\teval-rmspe:0.108758\n",
      "[114]\ttrain-rmse:0.096755\teval-rmse:0.103096\ttrain-rmspe:0.114538\teval-rmspe:0.108661\n",
      "[115]\ttrain-rmse:0.096415\teval-rmse:0.102869\ttrain-rmspe:0.114052\teval-rmspe:0.108415\n",
      "[116]\ttrain-rmse:0.096149\teval-rmse:0.102667\ttrain-rmspe:0.113689\teval-rmspe:0.108158\n",
      "[117]\ttrain-rmse:0.095946\teval-rmse:0.102546\ttrain-rmspe:0.113502\teval-rmspe:0.108046\n",
      "[118]\ttrain-rmse:0.09552\teval-rmse:0.102223\ttrain-rmspe:0.11306\teval-rmspe:0.107699\n",
      "[119]\ttrain-rmse:0.09536\teval-rmse:0.10211\ttrain-rmspe:0.112908\teval-rmspe:0.107587\n",
      "[120]\ttrain-rmse:0.095199\teval-rmse:0.102039\ttrain-rmspe:0.112688\teval-rmspe:0.107486\n",
      "[121]\ttrain-rmse:0.094949\teval-rmse:0.101878\ttrain-rmspe:0.112386\teval-rmspe:0.107323\n",
      "[122]\ttrain-rmse:0.094782\teval-rmse:0.101719\ttrain-rmspe:0.112225\teval-rmspe:0.107164\n",
      "[123]\ttrain-rmse:0.094557\teval-rmse:0.101574\ttrain-rmspe:0.112\teval-rmspe:0.107005\n",
      "[124]\ttrain-rmse:0.09428\teval-rmse:0.101387\ttrain-rmspe:0.111377\teval-rmspe:0.106717\n",
      "[125]\ttrain-rmse:0.094166\teval-rmse:0.101302\ttrain-rmspe:0.11128\teval-rmspe:0.106609\n",
      "[126]\ttrain-rmse:0.094039\teval-rmse:0.101171\ttrain-rmspe:0.11116\teval-rmspe:0.106533\n",
      "[127]\ttrain-rmse:0.093864\teval-rmse:0.101099\ttrain-rmspe:0.110566\teval-rmspe:0.10646\n",
      "[128]\ttrain-rmse:0.093579\teval-rmse:0.100861\ttrain-rmspe:0.110261\teval-rmspe:0.106201\n",
      "[129]\ttrain-rmse:0.093372\teval-rmse:0.100764\ttrain-rmspe:0.110076\teval-rmspe:0.106073\n",
      "[130]\ttrain-rmse:0.093243\teval-rmse:0.100667\ttrain-rmspe:0.109958\teval-rmspe:0.105982\n",
      "[131]\ttrain-rmse:0.093074\teval-rmse:0.100545\ttrain-rmspe:0.109802\teval-rmspe:0.105852\n",
      "[132]\ttrain-rmse:0.092865\teval-rmse:0.100355\ttrain-rmspe:0.109615\teval-rmspe:0.105609\n",
      "[133]\ttrain-rmse:0.092567\teval-rmse:0.100235\ttrain-rmspe:0.109248\teval-rmspe:0.105446\n",
      "[134]\ttrain-rmse:0.092424\teval-rmse:0.100133\ttrain-rmspe:0.109072\teval-rmspe:0.10531\n",
      "[135]\ttrain-rmse:0.092371\teval-rmse:0.100127\ttrain-rmspe:0.109047\teval-rmspe:0.105317\n",
      "[136]\ttrain-rmse:0.09219\teval-rmse:0.099998\ttrain-rmspe:0.108864\teval-rmspe:0.105141\n",
      "[137]\ttrain-rmse:0.091975\teval-rmse:0.099887\ttrain-rmspe:0.108655\teval-rmspe:0.10502\n",
      "[138]\ttrain-rmse:0.091779\teval-rmse:0.099818\ttrain-rmspe:0.108262\teval-rmspe:0.104902\n",
      "[139]\ttrain-rmse:0.091625\teval-rmse:0.099707\ttrain-rmspe:0.108093\teval-rmspe:0.104794\n",
      "[140]\ttrain-rmse:0.091452\teval-rmse:0.099604\ttrain-rmspe:0.107921\teval-rmspe:0.104675\n",
      "[141]\ttrain-rmse:0.091289\teval-rmse:0.099509\ttrain-rmspe:0.107721\teval-rmspe:0.104564\n",
      "[142]\ttrain-rmse:0.0911\teval-rmse:0.099407\ttrain-rmspe:0.107537\teval-rmspe:0.104465\n",
      "[143]\ttrain-rmse:0.090894\teval-rmse:0.099281\ttrain-rmspe:0.106996\teval-rmspe:0.104337\n",
      "[144]\ttrain-rmse:0.090788\teval-rmse:0.099223\ttrain-rmspe:0.106865\teval-rmspe:0.10427\n",
      "[145]\ttrain-rmse:0.090608\teval-rmse:0.099138\ttrain-rmspe:0.106649\teval-rmspe:0.104143\n",
      "[146]\ttrain-rmse:0.090444\teval-rmse:0.099015\ttrain-rmspe:0.106486\teval-rmspe:0.104038\n",
      "[147]\ttrain-rmse:0.090229\teval-rmse:0.098882\ttrain-rmspe:0.106181\teval-rmspe:0.103908\n",
      "[148]\ttrain-rmse:0.089917\teval-rmse:0.098605\ttrain-rmspe:0.10221\teval-rmspe:0.103595\n",
      "[149]\ttrain-rmse:0.089799\teval-rmse:0.098525\ttrain-rmspe:0.102036\teval-rmspe:0.103488\n",
      "[150]\ttrain-rmse:0.089639\teval-rmse:0.098412\ttrain-rmspe:0.101873\teval-rmspe:0.103379\n",
      "[151]\ttrain-rmse:0.08949\teval-rmse:0.09832\ttrain-rmspe:0.101689\teval-rmspe:0.103279\n",
      "[152]\ttrain-rmse:0.089408\teval-rmse:0.098286\ttrain-rmspe:0.101605\teval-rmspe:0.103242\n",
      "[153]\ttrain-rmse:0.089278\teval-rmse:0.098215\ttrain-rmspe:0.10148\teval-rmspe:0.103161\n",
      "[154]\ttrain-rmse:0.089079\teval-rmse:0.098038\ttrain-rmspe:0.101285\teval-rmspe:0.102999\n",
      "[155]\ttrain-rmse:0.08877\teval-rmse:0.09773\ttrain-rmspe:0.100884\teval-rmspe:0.102671\n",
      "[156]\ttrain-rmse:0.088698\teval-rmse:0.097688\ttrain-rmspe:0.100814\teval-rmspe:0.102627\n",
      "[157]\ttrain-rmse:0.088588\teval-rmse:0.097635\ttrain-rmspe:0.10067\teval-rmspe:0.10257\n",
      "[158]\ttrain-rmse:0.088326\teval-rmse:0.097467\ttrain-rmspe:0.100419\teval-rmspe:0.102401\n",
      "[159]\ttrain-rmse:0.088201\teval-rmse:0.097373\ttrain-rmspe:0.100384\teval-rmspe:0.1023\n",
      "[160]\ttrain-rmse:0.08802\teval-rmse:0.09728\ttrain-rmspe:0.100211\teval-rmspe:0.102209\n",
      "[161]\ttrain-rmse:0.087865\teval-rmse:0.097194\ttrain-rmspe:0.100045\teval-rmspe:0.102134\n",
      "[162]\ttrain-rmse:0.087711\teval-rmse:0.097107\ttrain-rmspe:0.099821\teval-rmspe:0.10204\n",
      "[163]\ttrain-rmse:0.087611\teval-rmse:0.097056\ttrain-rmspe:0.099717\teval-rmspe:0.101996\n",
      "[164]\ttrain-rmse:0.087498\teval-rmse:0.09701\ttrain-rmspe:0.099603\teval-rmspe:0.101944\n",
      "[165]\ttrain-rmse:0.087379\teval-rmse:0.096885\ttrain-rmspe:0.09946\teval-rmspe:0.10179\n",
      "[166]\ttrain-rmse:0.087305\teval-rmse:0.09685\ttrain-rmspe:0.099363\teval-rmspe:0.101755\n",
      "[167]\ttrain-rmse:0.087195\teval-rmse:0.096825\ttrain-rmspe:0.099256\teval-rmspe:0.101728\n",
      "[168]\ttrain-rmse:0.087065\teval-rmse:0.096716\ttrain-rmspe:0.099122\teval-rmspe:0.101606\n",
      "[169]\ttrain-rmse:0.086891\teval-rmse:0.096653\ttrain-rmspe:0.098835\teval-rmspe:0.101558\n",
      "[170]\ttrain-rmse:0.086759\teval-rmse:0.09658\ttrain-rmspe:0.098706\teval-rmspe:0.101495\n",
      "[171]\ttrain-rmse:0.086567\teval-rmse:0.096474\ttrain-rmspe:0.098506\teval-rmspe:0.101366\n",
      "[172]\ttrain-rmse:0.086378\teval-rmse:0.096293\ttrain-rmspe:0.098219\teval-rmspe:0.101153\n",
      "[173]\ttrain-rmse:0.086241\teval-rmse:0.09619\ttrain-rmspe:0.09806\teval-rmspe:0.101051\n",
      "[174]\ttrain-rmse:0.086103\teval-rmse:0.096138\ttrain-rmspe:0.096714\teval-rmspe:0.101002\n",
      "[175]\ttrain-rmse:0.085996\teval-rmse:0.096036\ttrain-rmspe:0.096511\teval-rmspe:0.100834\n",
      "[176]\ttrain-rmse:0.085904\teval-rmse:0.09598\ttrain-rmspe:0.096399\teval-rmspe:0.100781\n",
      "[177]\ttrain-rmse:0.085763\teval-rmse:0.095905\ttrain-rmspe:0.096087\teval-rmspe:0.100706\n",
      "[178]\ttrain-rmse:0.085579\teval-rmse:0.09579\ttrain-rmspe:0.095907\teval-rmspe:0.100568\n",
      "[179]\ttrain-rmse:0.085527\teval-rmse:0.09576\ttrain-rmspe:0.095853\teval-rmspe:0.100541\n",
      "[180]\ttrain-rmse:0.085321\teval-rmse:0.095616\ttrain-rmspe:0.09562\teval-rmspe:0.100392\n",
      "[181]\ttrain-rmse:0.085113\teval-rmse:0.095512\ttrain-rmspe:0.095366\teval-rmspe:0.100306\n",
      "[182]\ttrain-rmse:0.085008\teval-rmse:0.095485\ttrain-rmspe:0.095241\teval-rmspe:0.10026\n",
      "[183]\ttrain-rmse:0.084859\teval-rmse:0.095404\ttrain-rmspe:0.095052\teval-rmspe:0.100181\n",
      "[184]\ttrain-rmse:0.084717\teval-rmse:0.095213\ttrain-rmspe:0.094903\teval-rmspe:0.09987\n",
      "[185]\ttrain-rmse:0.084657\teval-rmse:0.095175\ttrain-rmspe:0.094845\teval-rmspe:0.099839\n",
      "[186]\ttrain-rmse:0.084457\teval-rmse:0.095077\ttrain-rmspe:0.094629\teval-rmspe:0.099738\n",
      "[187]\ttrain-rmse:0.084312\teval-rmse:0.095058\ttrain-rmspe:0.0944\teval-rmspe:0.0997\n",
      "[188]\ttrain-rmse:0.084189\teval-rmse:0.095017\ttrain-rmspe:0.094271\teval-rmspe:0.099654\n",
      "[189]\ttrain-rmse:0.084109\teval-rmse:0.095021\ttrain-rmspe:0.094184\teval-rmspe:0.099652\n",
      "[190]\ttrain-rmse:0.083973\teval-rmse:0.09495\ttrain-rmspe:0.093959\teval-rmspe:0.099497\n",
      "[191]\ttrain-rmse:0.083897\teval-rmse:0.094918\ttrain-rmspe:0.093793\teval-rmspe:0.099454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[192]\ttrain-rmse:0.083801\teval-rmse:0.09486\ttrain-rmspe:0.093695\teval-rmspe:0.099373\n",
      "[193]\ttrain-rmse:0.083734\teval-rmse:0.094777\ttrain-rmspe:0.093574\teval-rmspe:0.099254\n",
      "[194]\ttrain-rmse:0.083657\teval-rmse:0.094769\ttrain-rmspe:0.093479\teval-rmspe:0.09925\n",
      "[195]\ttrain-rmse:0.083553\teval-rmse:0.094757\ttrain-rmspe:0.09339\teval-rmspe:0.099233\n",
      "[196]\ttrain-rmse:0.083362\teval-rmse:0.094637\ttrain-rmspe:0.093185\teval-rmspe:0.099107\n",
      "[197]\ttrain-rmse:0.083217\teval-rmse:0.094506\ttrain-rmspe:0.093001\teval-rmspe:0.098907\n",
      "[198]\ttrain-rmse:0.082988\teval-rmse:0.094368\ttrain-rmspe:0.092773\teval-rmspe:0.098764\n",
      "[199]\ttrain-rmse:0.082905\teval-rmse:0.094342\ttrain-rmspe:0.092689\teval-rmspe:0.098717\n",
      "[200]\ttrain-rmse:0.082812\teval-rmse:0.094307\ttrain-rmspe:0.092596\teval-rmspe:0.098675\n",
      "[201]\ttrain-rmse:0.08268\teval-rmse:0.094218\ttrain-rmspe:0.092447\teval-rmspe:0.09859\n",
      "[202]\ttrain-rmse:0.082572\teval-rmse:0.094144\ttrain-rmspe:0.092298\teval-rmspe:0.098488\n",
      "[203]\ttrain-rmse:0.082503\teval-rmse:0.094106\ttrain-rmspe:0.092215\teval-rmspe:0.098461\n",
      "[204]\ttrain-rmse:0.082409\teval-rmse:0.094085\ttrain-rmspe:0.092091\teval-rmspe:0.098423\n",
      "[205]\ttrain-rmse:0.082111\teval-rmse:0.093809\ttrain-rmspe:0.091765\teval-rmspe:0.098116\n",
      "[206]\ttrain-rmse:0.082014\teval-rmse:0.09377\ttrain-rmspe:0.091653\teval-rmspe:0.098081\n",
      "[207]\ttrain-rmse:0.081901\teval-rmse:0.093673\ttrain-rmspe:0.091462\teval-rmspe:0.097935\n",
      "[208]\ttrain-rmse:0.081778\teval-rmse:0.093589\ttrain-rmspe:0.091306\teval-rmspe:0.097841\n",
      "[209]\ttrain-rmse:0.081632\teval-rmse:0.093549\ttrain-rmspe:0.09116\teval-rmspe:0.097795\n",
      "[210]\ttrain-rmse:0.081477\teval-rmse:0.093494\ttrain-rmspe:0.090995\teval-rmspe:0.097729\n",
      "[211]\ttrain-rmse:0.081386\teval-rmse:0.093446\ttrain-rmspe:0.090909\teval-rmspe:0.097681\n",
      "[212]\ttrain-rmse:0.081324\teval-rmse:0.09345\ttrain-rmspe:0.090838\teval-rmspe:0.097671\n",
      "[213]\ttrain-rmse:0.08124\teval-rmse:0.093439\ttrain-rmspe:0.090701\teval-rmspe:0.097671\n",
      "[214]\ttrain-rmse:0.081174\teval-rmse:0.093411\ttrain-rmspe:0.090637\teval-rmspe:0.097639\n",
      "[215]\ttrain-rmse:0.081083\teval-rmse:0.093374\ttrain-rmspe:0.090539\teval-rmspe:0.097611\n",
      "[216]\ttrain-rmse:0.081\teval-rmse:0.093346\ttrain-rmspe:0.090448\teval-rmspe:0.097586\n",
      "[217]\ttrain-rmse:0.080937\teval-rmse:0.093319\ttrain-rmspe:0.089959\teval-rmspe:0.097563\n",
      "[218]\ttrain-rmse:0.080704\teval-rmse:0.093097\ttrain-rmspe:0.089727\teval-rmspe:0.097336\n",
      "[219]\ttrain-rmse:0.080495\teval-rmse:0.092956\ttrain-rmspe:0.089479\teval-rmspe:0.097202\n",
      "[220]\ttrain-rmse:0.080427\teval-rmse:0.092939\ttrain-rmspe:0.089415\teval-rmspe:0.097179\n",
      "[221]\ttrain-rmse:0.080329\teval-rmse:0.092919\ttrain-rmspe:0.089307\teval-rmspe:0.097167\n",
      "[222]\ttrain-rmse:0.080225\teval-rmse:0.092862\ttrain-rmspe:0.089187\teval-rmspe:0.097099\n",
      "[223]\ttrain-rmse:0.080138\teval-rmse:0.092832\ttrain-rmspe:0.089101\teval-rmspe:0.097054\n",
      "[224]\ttrain-rmse:0.08009\teval-rmse:0.092822\ttrain-rmspe:0.08905\teval-rmspe:0.097042\n",
      "[225]\ttrain-rmse:0.080008\teval-rmse:0.092778\ttrain-rmspe:0.088974\teval-rmspe:0.097005\n",
      "[226]\ttrain-rmse:0.079961\teval-rmse:0.092769\ttrain-rmspe:0.088927\teval-rmspe:0.097008\n",
      "[227]\ttrain-rmse:0.079789\teval-rmse:0.092662\ttrain-rmspe:0.088731\teval-rmspe:0.096901\n",
      "[228]\ttrain-rmse:0.079718\teval-rmse:0.092642\ttrain-rmspe:0.088666\teval-rmspe:0.096885\n",
      "[229]\ttrain-rmse:0.07966\teval-rmse:0.092646\ttrain-rmspe:0.088612\teval-rmspe:0.096899\n",
      "[230]\ttrain-rmse:0.079595\teval-rmse:0.092675\ttrain-rmspe:0.088517\teval-rmspe:0.096917\n",
      "[231]\ttrain-rmse:0.079525\teval-rmse:0.092646\ttrain-rmspe:0.088435\teval-rmspe:0.096889\n",
      "[232]\ttrain-rmse:0.079439\teval-rmse:0.09258\ttrain-rmspe:0.088344\teval-rmspe:0.096823\n",
      "[233]\ttrain-rmse:0.079297\teval-rmse:0.092486\ttrain-rmspe:0.088112\teval-rmspe:0.096652\n",
      "[234]\ttrain-rmse:0.079207\teval-rmse:0.092402\ttrain-rmspe:0.087999\teval-rmspe:0.096524\n",
      "[235]\ttrain-rmse:0.079164\teval-rmse:0.092384\ttrain-rmspe:0.087953\teval-rmspe:0.096507\n",
      "[236]\ttrain-rmse:0.079095\teval-rmse:0.092348\ttrain-rmspe:0.087846\teval-rmspe:0.096437\n",
      "[237]\ttrain-rmse:0.078995\teval-rmse:0.092313\ttrain-rmspe:0.087703\teval-rmspe:0.096411\n",
      "[238]\ttrain-rmse:0.078922\teval-rmse:0.092307\ttrain-rmspe:0.087625\teval-rmspe:0.096402\n",
      "[239]\ttrain-rmse:0.078853\teval-rmse:0.092248\ttrain-rmspe:0.087477\teval-rmspe:0.096323\n",
      "[240]\ttrain-rmse:0.078731\teval-rmse:0.092227\ttrain-rmspe:0.087329\teval-rmspe:0.096309\n",
      "[241]\ttrain-rmse:0.07865\teval-rmse:0.092172\ttrain-rmspe:0.087234\teval-rmspe:0.096249\n",
      "[242]\ttrain-rmse:0.078543\teval-rmse:0.092145\ttrain-rmspe:0.086942\teval-rmspe:0.096206\n",
      "[243]\ttrain-rmse:0.078511\teval-rmse:0.092134\ttrain-rmspe:0.086911\teval-rmspe:0.096196\n",
      "[244]\ttrain-rmse:0.078464\teval-rmse:0.092121\ttrain-rmspe:0.086875\teval-rmspe:0.096182\n",
      "[245]\ttrain-rmse:0.078379\teval-rmse:0.09207\ttrain-rmspe:0.086707\teval-rmspe:0.096124\n",
      "[246]\ttrain-rmse:0.078304\teval-rmse:0.092061\ttrain-rmspe:0.086584\teval-rmspe:0.096111\n",
      "[247]\ttrain-rmse:0.078244\teval-rmse:0.092047\ttrain-rmspe:0.08652\teval-rmspe:0.096104\n",
      "[248]\ttrain-rmse:0.078161\teval-rmse:0.092006\ttrain-rmspe:0.086433\teval-rmspe:0.096071\n",
      "[249]\ttrain-rmse:0.078002\teval-rmse:0.091926\ttrain-rmspe:0.086206\teval-rmspe:0.09601\n",
      "[250]\ttrain-rmse:0.077878\teval-rmse:0.091898\ttrain-rmspe:0.086053\teval-rmspe:0.095978\n",
      "[251]\ttrain-rmse:0.077773\teval-rmse:0.091879\ttrain-rmspe:0.08591\teval-rmspe:0.095945\n",
      "[252]\ttrain-rmse:0.077668\teval-rmse:0.091856\ttrain-rmspe:0.085802\teval-rmspe:0.095919\n",
      "[253]\ttrain-rmse:0.077636\teval-rmse:0.091867\ttrain-rmspe:0.085774\teval-rmspe:0.095928\n",
      "[254]\ttrain-rmse:0.077592\teval-rmse:0.091851\ttrain-rmspe:0.08573\teval-rmspe:0.095914\n",
      "[255]\ttrain-rmse:0.077496\teval-rmse:0.091832\ttrain-rmspe:0.085588\teval-rmspe:0.095896\n",
      "[256]\ttrain-rmse:0.077406\teval-rmse:0.091788\ttrain-rmspe:0.085497\teval-rmspe:0.09585\n",
      "[257]\ttrain-rmse:0.077336\teval-rmse:0.091756\ttrain-rmspe:0.085424\teval-rmspe:0.095832\n",
      "[258]\ttrain-rmse:0.077298\teval-rmse:0.091735\ttrain-rmspe:0.085394\teval-rmspe:0.095815\n",
      "[259]\ttrain-rmse:0.077202\teval-rmse:0.09167\ttrain-rmspe:0.085298\teval-rmspe:0.09574\n",
      "[260]\ttrain-rmse:0.077123\teval-rmse:0.091677\ttrain-rmspe:0.08519\teval-rmspe:0.095742\n",
      "[261]\ttrain-rmse:0.077082\teval-rmse:0.091671\ttrain-rmspe:0.085146\teval-rmspe:0.095734\n",
      "[262]\ttrain-rmse:0.077006\teval-rmse:0.09162\ttrain-rmspe:0.084363\teval-rmspe:0.095682\n",
      "[263]\ttrain-rmse:0.076917\teval-rmse:0.091621\ttrain-rmspe:0.084251\teval-rmspe:0.095687\n",
      "[264]\ttrain-rmse:0.076865\teval-rmse:0.091575\ttrain-rmspe:0.084199\teval-rmspe:0.095638\n",
      "[265]\ttrain-rmse:0.076756\teval-rmse:0.091525\ttrain-rmspe:0.08409\teval-rmspe:0.095587\n",
      "[266]\ttrain-rmse:0.0767\teval-rmse:0.09147\ttrain-rmspe:0.084038\teval-rmspe:0.095528\n",
      "[267]\ttrain-rmse:0.076649\teval-rmse:0.091455\ttrain-rmspe:0.083692\teval-rmspe:0.095513\n",
      "[268]\ttrain-rmse:0.076489\teval-rmse:0.091366\ttrain-rmspe:0.083532\teval-rmspe:0.095422\n",
      "[269]\ttrain-rmse:0.0764\teval-rmse:0.091353\ttrain-rmspe:0.082725\teval-rmspe:0.095415\n",
      "[270]\ttrain-rmse:0.076333\teval-rmse:0.091203\ttrain-rmspe:0.082635\teval-rmspe:0.095341\n",
      "[271]\ttrain-rmse:0.076225\teval-rmse:0.091107\ttrain-rmspe:0.08253\teval-rmspe:0.09524\n",
      "[272]\ttrain-rmse:0.076149\teval-rmse:0.091103\ttrain-rmspe:0.082441\teval-rmspe:0.095237\n",
      "[273]\ttrain-rmse:0.07605\teval-rmse:0.091048\ttrain-rmspe:0.0823\teval-rmspe:0.095179\n",
      "[274]\ttrain-rmse:0.075956\teval-rmse:0.091071\ttrain-rmspe:0.082173\teval-rmspe:0.09521\n",
      "[275]\ttrain-rmse:0.075856\teval-rmse:0.091079\ttrain-rmspe:0.081958\teval-rmspe:0.095212\n",
      "[276]\ttrain-rmse:0.075805\teval-rmse:0.091044\ttrain-rmspe:0.081899\teval-rmspe:0.095179\n",
      "[277]\ttrain-rmse:0.075725\teval-rmse:0.091005\ttrain-rmspe:0.081806\teval-rmspe:0.095136\n",
      "[278]\ttrain-rmse:0.07563\teval-rmse:0.090984\ttrain-rmspe:0.081701\teval-rmspe:0.095121\n",
      "[279]\ttrain-rmse:0.075564\teval-rmse:0.090993\ttrain-rmspe:0.08159\teval-rmspe:0.095125\n",
      "[280]\ttrain-rmse:0.075502\teval-rmse:0.090984\ttrain-rmspe:0.081533\teval-rmspe:0.095107\n",
      "[281]\ttrain-rmse:0.075432\teval-rmse:0.090951\ttrain-rmspe:0.081459\teval-rmspe:0.095077\n",
      "[282]\ttrain-rmse:0.075351\teval-rmse:0.090953\ttrain-rmspe:0.081374\teval-rmspe:0.095106\n",
      "[283]\ttrain-rmse:0.075242\teval-rmse:0.090898\ttrain-rmspe:0.08123\teval-rmspe:0.095058\n",
      "[284]\ttrain-rmse:0.075167\teval-rmse:0.090903\ttrain-rmspe:0.081077\teval-rmspe:0.095075\n",
      "[285]\ttrain-rmse:0.075086\teval-rmse:0.090895\ttrain-rmspe:0.080983\teval-rmspe:0.095065\n",
      "[286]\ttrain-rmse:0.075037\teval-rmse:0.090859\ttrain-rmspe:0.080928\teval-rmspe:0.095032\n",
      "[287]\ttrain-rmse:0.074965\teval-rmse:0.090806\ttrain-rmspe:0.080855\teval-rmspe:0.094985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[288]\ttrain-rmse:0.074867\teval-rmse:0.090771\ttrain-rmspe:0.080737\teval-rmspe:0.094959\n",
      "[289]\ttrain-rmse:0.07478\teval-rmse:0.090766\ttrain-rmspe:0.080597\teval-rmspe:0.094956\n",
      "[290]\ttrain-rmse:0.074753\teval-rmse:0.090751\ttrain-rmspe:0.080574\teval-rmspe:0.094943\n",
      "[291]\ttrain-rmse:0.074664\teval-rmse:0.090701\ttrain-rmspe:0.080367\teval-rmspe:0.094896\n",
      "[292]\ttrain-rmse:0.074592\teval-rmse:0.090653\ttrain-rmspe:0.08023\teval-rmspe:0.094788\n",
      "[293]\ttrain-rmse:0.074534\teval-rmse:0.090642\ttrain-rmspe:0.080119\teval-rmspe:0.094768\n",
      "[294]\ttrain-rmse:0.074459\teval-rmse:0.09058\ttrain-rmspe:0.080021\teval-rmspe:0.094689\n",
      "[295]\ttrain-rmse:0.0744\teval-rmse:0.090585\ttrain-rmspe:0.079954\teval-rmspe:0.094701\n",
      "[296]\ttrain-rmse:0.074349\teval-rmse:0.090564\ttrain-rmspe:0.079904\teval-rmspe:0.094681\n",
      "[297]\ttrain-rmse:0.074293\teval-rmse:0.090551\ttrain-rmspe:0.07983\teval-rmspe:0.094658\n",
      "[298]\ttrain-rmse:0.074257\teval-rmse:0.090555\ttrain-rmspe:0.079793\teval-rmspe:0.09466\n",
      "[299]\ttrain-rmse:0.074197\teval-rmse:0.090554\ttrain-rmspe:0.079696\teval-rmspe:0.094664\n"
     ]
    }
   ],
   "source": [
    "['Store', 'CompetitionDistance', 'Promo', 'Promo2', 'SchoolHoliday', 'StoreType', 'Assortment', 'StateHoliday', 'DayOfWeek', 'Month', 'Day', 'Year', 'WeekOfYear', 'CompetitionOpen', 'PromoOpen', 'IsPromoMonth']\n",
    "\n",
    "print(\"Train a XGBoost model\")\n",
    "X_train, X_valid = train_test_split(train, test_size=0.012, random_state=10)\n",
    "y_train = np.log1p(X_train.Sales)\n",
    "y_valid = np.log1p(X_valid.Sales)\n",
    "dtrain = xgb.DMatrix(X_train[features], y_train)\n",
    "dvalid = xgb.DMatrix(X_valid[features], y_valid)\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, \\\n",
    "  early_stopping_rounds=100, feval=rmspe_xg, verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating\n",
      "RMSPE: 0.094663\n"
     ]
    }
   ],
   "source": [
    "print(\"Validating\")\n",
    "yhat = gbm.predict(xgb.DMatrix(X_valid[features]))\n",
    "error = rmspe(X_valid.Sales.values, np.expm1(yhat))\n",
    "print('RMSPE: {:.6f}'.format(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make predictions on the test set\n"
     ]
    }
   ],
   "source": [
    "print(\"Make predictions on the test set\")\n",
    "dtest = xgb.DMatrix(test[features])\n",
    "test_probs = gbm.predict(dtest)\n",
    "# Make Submission\n",
    "result = pd.DataFrame({\"Id\": test[\"Id\"], 'Sales': np.expm1(test_probs)})\n",
    "result.to_csv(\"xgboost_10_submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_feature_map(features)\n",
    "importance = gbm.get_fscore(fmap='xgb.fmap')\n",
    "importance = sorted(importance.items(), key=operator.itemgetter(1))\n",
    "\n",
    "df = pd.DataFrame(importance, columns=['feature', 'fscore'])\n",
    "df['fscore'] = df['fscore'] / df['fscore'].sum()\n",
    "\n",
    "featp = df.plot(kind='barh', x='feature', y='fscore', legend=False, figsize=(6, 10))\n",
    "plt.title('XGBoost Feature Importance')\n",
    "plt.xlabel('relative importance')\n",
    "fig_featp = featp.get_figure()\n",
    "fig_featp.savefig('feature_importance_xgb.png', bbox_inches='tight', pad_inches=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
